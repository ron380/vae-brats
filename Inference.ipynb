{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IPyWidget Viewer \n",
    "\n",
    "I did a viewer using ipywidgets that allows to visualize the results, with the slider you can move the deepth in the z-axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import FloatSlider\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display,clear_output\n",
    "from IPython.display import display\n",
    "import IPython\n",
    "from ipywidgets import Output\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk  # For loading the dataset\n",
    "import numpy as np  # For data manipulation\n",
    "from model import build_model, dice_coefficient  # For creating the model\n",
    "import glob  # For populating the list of files\n",
    "from scipy.ndimage import zoom  # For resizing\n",
    "import re  # For parsing the filenames (to know their modality)\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from keras.models import load_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_label(img):\n",
    "    kernel = np.ones((3, 3))\n",
    "    imgo = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    kernel = np.ones((3, 3))\n",
    "    imgo = cv2.dilate(imgo, kernel, iterations=1)\n",
    "    return imgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_path):\n",
    "    \"\"\"\n",
    "    Reads a .nii.gz image and returns as a numpy array.\n",
    "    \"\"\"\n",
    "    return sitk.GetArrayFromImage(sitk.ReadImage(img_path))\n",
    "\n",
    "def resize(img, shape, mode='constant', orig_shape=(155, 240, 240)):\n",
    "    \"\"\"\n",
    "    Wrapper for scipy.ndimage.zoom suited for MRI images.\n",
    "    \"\"\"\n",
    "    assert len(shape) == 3, \"Can not have more than 3 dimensions\"\n",
    "    factors = (\n",
    "        shape[0]/orig_shape[0],\n",
    "        shape[1]/orig_shape[1], \n",
    "        shape[2]/orig_shape[2]\n",
    "    )\n",
    "    \n",
    "    # Resize to the given shape\n",
    "    return zoom(img, factors, mode=mode)\n",
    "\n",
    "\n",
    "def preprocess(img, out_shape=None):\n",
    "    \"\"\"\n",
    "    Preprocess the image.\n",
    "    Just an example, you can add more preprocessing steps if you wish to.\n",
    "    \"\"\"\n",
    "    if out_shape is not None:\n",
    "        img = resize(img, out_shape, mode='constant')\n",
    "    \n",
    "    # Normalize the image\n",
    "    mean = img.mean()\n",
    "    std = img.std()\n",
    "    return (img - mean) / std\n",
    "\n",
    "\n",
    "def preprocess_label(img, out_shape=None, mode='nearest'):\n",
    "    \"\"\"\n",
    "    Separates out the 3 labels from the segmentation provided, namely:\n",
    "    GD-enhancing tumor (ET — label 4), the peritumoral edema (ED — label 2))\n",
    "    and the necrotic and non-enhancing tumor core (NCR/NET — label 1)\n",
    "    \"\"\"\n",
    "    #ncr = img == 1  # Necrotic and Non-Enhancing Tumor (NCR/NET)\n",
    "    ed = img == 2  # Peritumoral Edema (ED)\n",
    "    et = img == 4  # GD-enhancing Tumor (ET)\n",
    "    \n",
    "    if out_shape is not None:\n",
    "        #ncr = resize(ncr, out_shape, mode=mode)\n",
    "        ed = resize(ed, out_shape, mode=mode)\n",
    "        et = resize(et, out_shape, mode=mode)\n",
    "\n",
    "    return np.array([ed, et], dtype=np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required to run on RXT GPU Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_config = ConfigProto()\n",
    "gpu_config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=gpu_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class viewer:\n",
    "    def __init__(self, img,pred):\n",
    "        self.tab = widgets.Tab()\n",
    "        self.childrens = []\n",
    "        self.tab.children = []\n",
    "        self.tab.set_title(0, 'Segmentation')\n",
    "        self.tab.set_title(1, 'Nifti Information')\n",
    "        self.mri_img = img\n",
    "        self.mri_prediction = pred #resize(pred,self.mri_img.pixel_array.shape)  #np.zeros(512*512).reshape((512,512))\n",
    "        \n",
    "        self.mri_payload = self.mri_img #np.array(self.mri_img.dataobj)#np.copy(self.mri_img.pixel_array)\n",
    "        self.mri_slide = self.mri_payload[:,:,10] \n",
    "        self.mri_pred_slide = self.mri_prediction[:,:,10] \n",
    "        \n",
    "        \n",
    "        self.tab_segmentation()\n",
    "        self.tab_dicominformation()\n",
    "        self.display()\n",
    "        \n",
    "    def tab_segmentation(self):\n",
    "        self.mri_slider = widgets.IntSlider(min=0, max=self.mri_payload.shape[2]-1, step=1,value=10,orientation='vertical',description='Deep',layout=Layout(width='150px'))\n",
    "        self.out_mri = widgets.Output(layout=Layout(height='{}px'.format(self.mri_slide.shape[0]), width = '{}px'.format(self.mri_slide.shape[1]), border='None'))\n",
    "        self.out_prediction = widgets.Output(layout=Layout(height='{}px'.format(self.mri_slide.shape[0]), width = '{}px'.format(self.mri_slide.shape[1]), border='None'))\n",
    "        self.out_overlap = widgets.Output(layout=Layout(height='{}px'.format(self.mri_slide.shape[0]), width = '{}px'.format(self.mri_slide.shape[1]), border='None'))\n",
    "        scale=4\n",
    "        def update_mri_plot(value):\n",
    "            self.mri_slide = self.mri_payload[:,:,value]\n",
    "            fig, axes = plt.subplots()\n",
    "            axes.set_title('Original MRI')\n",
    "            dpi = fig.get_dpi()\n",
    "            fig.set_size_inches(self.mri_slide.shape[0]/float(dpi)*scale,self.mri_slide.shape[1]/float(dpi)*scale)\n",
    "            axes.imshow(self.mri_slide,cmap='bone')\n",
    "            plt.show(fig)\n",
    "                    \n",
    "            \n",
    "        def plot_overlap(value):\n",
    "            fig, axes = plt.subplots()\n",
    "            axes.set_title('Overlap')\n",
    "            dpi = fig.get_dpi()\n",
    "            fig.set_size_inches(self.mri_prediction.shape[0]/float(dpi)*scale,self.mri_prediction.shape[1]/float(dpi)*scale)\n",
    "            axes.imshow(self.mri_slide+ self.mri_pred_slide*np.max(self.mri_slide))\n",
    "            plt.show(fig)\n",
    "            \n",
    "        def plot_prediction(value):\n",
    "            self.mri_pred_slide = self.mri_prediction[:,:,value]\n",
    "            img = self.mri_pred_slide #resize(self.mri_prediction,self.mri_img.pixel_array.shape) \n",
    "            fig, axes = plt.subplots()\n",
    "            axes.set_title('Prediction')\n",
    "            dpi = fig.get_dpi()\n",
    "            fig.set_size_inches(self.mri_prediction.shape[0]/float(dpi)*scale,self.mri_prediction.shape[1]/float(dpi)*scale)\n",
    "            axes.imshow(self.mri_pred_slide)\n",
    "            #axes.imshow(self.mri_pred_slide)\n",
    "            plt.show(fig)\n",
    "                    \n",
    "        with self.out_mri :\n",
    "            img0 = interactive(update_mri_plot, value=self.mri_slider)\n",
    "            self.mri_slider.value=13\n",
    "        \n",
    "        \n",
    "        with self.out_prediction :\n",
    "            img2 = interactive(plot_prediction, value=self.mri_slider)\n",
    "            self.mri_slider.value=11\n",
    "        \n",
    "        with self.out_overlap :\n",
    "            img3 = interactive(plot_overlap, value=self.mri_slider)\n",
    "            self.mri_slider.value=10\n",
    "                \n",
    "            \n",
    "        self.hbox=widgets.HBox([img0.children[0],img0.children[1],img2.children[1],img3.children[1]])\n",
    "\n",
    "        self.childrens.append(self.hbox) \n",
    "        \n",
    "    def tab_dicominformation(self):\n",
    "        pass\n",
    "    def display(self):\n",
    "        #self.tab.children = self.childrens\n",
    "        display(self.hbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dummy_loss(y_true, y_pred):\n",
    "    return y_pred\n",
    "\n",
    "#load_model('vaemode.h5', custom_objects={'dummy_loss':dummy_loss})\n",
    "model=load_model('brast-models/model-vae.h5',custom_objects={'loss_':dummy_loss,'dice_coefficient':dice_coefficient} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for prediction (read this very carefull!)\n",
    "\n",
    "This is a multiclass segmentation model, the input data for the model are four cubes of data then\n",
    "the Input Shape is (4, 128, 128, 128), 4 channels [\"t1\", \"t1ce\", \"flair\", \"t2\"]\n",
    "\n",
    "The output are labels 1,2,4 (this will be fixed when I train it again)\n",
    "\n",
    "labels explanation:\n",
    "* GD-enhancing tumor (ET — label 4)\n",
    "* The peritumoral edema (ED — label 2)\n",
    "* Non-enhancing tumor (NCR/NET — label 1)\n",
    "\n",
    "\n",
    "\n",
    "<h1 style=\"color: red;\"> That means that to evaluate the data of a patient in the hostpital we will need the four images (\"t1\", \"t1ce\", \"flair\", \"t2\") for a single patient</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw input files\n",
    "mri_file_t1    = 'brast-validation/2019/MICCAI_BraTS_2019_Data_Validation/BraTS19_CBICA_AAM_1/BraTS19_CBICA_AAM_1_t1.nii.gz'\n",
    "mri_file_t1ce  = 'brast-validation/2019/MICCAI_BraTS_2019_Data_Validation/BraTS19_CBICA_AAM_1/BraTS19_CBICA_AAM_1_t1ce.nii.gz'\n",
    "mri_file_flair = 'brast-validation/2019/MICCAI_BraTS_2019_Data_Validation/BraTS19_CBICA_AAM_1/BraTS19_CBICA_AAM_1_flair.nii.gz'\n",
    "mri_file_t2    = 'brast-validation/2019/MICCAI_BraTS_2019_Data_Validation/BraTS19_CBICA_AAM_1/BraTS19_CBICA_AAM_1_t2.nii.gz'\n",
    "\n",
    "# output with bias correction using itk/ants\n",
    "#mri_file_t1_out    = 'output/data/valid/preprocessed/BraTS19_CBICA_AAM_1_t1_out.nii.gz'\n",
    "#mri_file_t1ce_out  = 'output/data/valid/preprocessed/BraTS19_CBICA_AAM_1_t1ce_out.nii.gz'\n",
    "#mri_file_flair_out = 'output/data/valid/preprocessed/BraTS19_CBICA_AAM_1_flair_out.nii.gz'\n",
    "#mri_file_t2_out    = 'output/data/valid/preprocessed/BraTS19_CBICA_AAM_1_t2_out.nii.gz'\n",
    "\n",
    "#mri_file_t1_out = mri_file_t1\n",
    "#mri_file_t1ce_out = mri_file_t1ce\n",
    "#mri_file_flair_out = mri_file_flair\n",
    "#mri_file_t2_out = mri_file_t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading images\n",
    "\n",
    "the pre-trained model <a href='https://github.com/ellisdg/3DUnetCNN#pre-trained-models'>https://github.com/ellisdg/3DUnetCNN#pre-trained-models</a>\n",
    "was trained with a input shape of (128,128,128) for every category  [\"t1\", \"t1ce\", \"flair\", \"t2\"],\n",
    "the read_image function allows to read and resize the cube of data.\n",
    "\n",
    "The final shape for the event(Tensor) to be evaluate should be (4,128,128,128)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 192, 128)\n",
      "(160, 192, 128)\n",
      "(160, 192, 128)\n",
      "(160, 192, 128)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (4, 160, 192, 128)\n",
    "output_channels = 2\n",
    "\n",
    "def read_image(mrifile,input_shape):\n",
    "    return preprocess(read_img(mrifile), input_shape[1:])\n",
    "\n",
    "mri_t1=read_image(mri_file_t1,input_shape)\n",
    "mri_t1ce=read_image(mri_file_t1ce,input_shape)\n",
    "mri_flair=read_image(mri_file_flair,input_shape)\n",
    "mri_t2=read_image(mri_file_t2,input_shape)\n",
    "#mri_label = read_image(label_file,img_shape)\n",
    "\n",
    "\n",
    "#mri_t1=np.array(mri_t1.dataobj)\n",
    "#mri_t1ce=np.array(mri_t1ce.dataobj)\n",
    "#mri_flair=np.array(mri_flair.dataobj)\n",
    "#mri_t2=np.array(mri_t2.dataobj)\n",
    "#mri_label = np.array(mri_label.dataobj)\n",
    "\n",
    "print(mri_t1.shape)\n",
    "print(mri_t1ce.shape)\n",
    "print(mri_flair.shape)\n",
    "print(mri_t2.shape)\n",
    "#print(mri_label.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarization\n",
    "they call it normalization but it is more like a data standarization \n",
    "because they are subtranting the mean and dividing by the standar deviation  \n",
    "\n",
    "their code snippet\n",
    "```py\n",
    "def normalize_data(data, mean, std):\n",
    "    data -= mean[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "    data /= std[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "    return data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the event\n",
    "\n",
    "The four cube of images( ['t1', 't2', 't1ce', 'flair']) in a single tensor.\n",
    "\n",
    "Shape (4,128,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 160, 192, 128)\n"
     ]
    }
   ],
   "source": [
    "event=np.array([mri_t1,mri_t2,mri_t1ce,mri_flair])\n",
    "print(event.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "I am using the default parameters that they are using for training, \n",
    "you can see that in config dictionary import it from the treining module.\n",
    "```\n",
    "from brats.train import config\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(np.array([event]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plabel2=pred[0,0,:,:,:]\n",
    "plabel4=pred[0,1,:,:,:]\n",
    "\n",
    "plabel2 = post_process_label(plabel2)\n",
    "plabel4 = post_process_label(plabel4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualization \n",
    "\n",
    "using the viewer that I did, you can to visualize the results,\n",
    "maybe you can play in the prediction cell with the parameters to get better results or you can to post process it to filter some noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results label 4 (GD-enhancing tumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5a99e51e74474d935e66c29789ee1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=10, description='Deep', layout=Layout(width='150px'), max=127, orientation='ver…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.viewer at 0x7fe7784cb5f8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer(mri_t1,plabel4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results label 2 (The peritumoral edema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32efae901b4640d4a07b49c36eeb0ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=10, description='Deep', layout=Layout(width='150px'), max=127, orientation='ver…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.viewer at 0x7fe6648fcc18>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer(mri_t1,plabel2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b19f22de374fd1be92c991f50e9043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=10, description='Deep', layout=Layout(width='150px'), max=127, orientation='ver…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.viewer at 0x7fe63837d5f8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer(mri_t1,plabel2+(plabel4*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Visualization using ipyvolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "import ipyvolume.pylab as p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.6/site-packages/ipyvolume/serialize.py:81: RuntimeWarning: invalid value encountered in true_divide\n",
      "  gradient = gradient / np.sqrt(gradient[0]**2 + gradient[1]**2 + gradient[2]**2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df66e40ff1fc4128bb45301eda9f7f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.1, max=1.0, step=0.00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.figure()\n",
    "ipv.volshow(plabel2)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9724f17c74f47ce922e3ba8243b4f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.1, max=1.0, step=0.00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.figure()\n",
    "ipv.volshow(plabel4)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80e6e3ae616400498f45fe71269f470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.1, max=1.0, step=0.00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.figure()\n",
    "ipv.volshow(mri_t1*0.6+plabel4*500+plabel2*255)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
